{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC3gcRQNLUxn",
        "outputId": "799f7ae6-d096-46a9-861d-228a7cf46cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.18.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "‚úÖ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow tensorflow-hub opencv-python-headless matplotlib numpy pillow\n",
        "!pip install imageio[ffmpeg] scipy scikit-learn\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "import math\n",
        "from collections import deque\n",
        "import time\n",
        "from scipy import ndimage\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UltraAccurateFallDetector:\n",
        "    def __init__(self):\n",
        "        print(\" Loading MoveNet model...\")\n",
        "        # Load MoveNet model\n",
        "        self.model = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n",
        "        self.movenet = self.model.signatures['serving_default']\n",
        "        print(\" MoveNet model loaded!\")\n",
        "\n",
        "        # Multi-detection buffers\n",
        "        self.pose_buffer = deque(maxlen=10)\n",
        "        self.motion_buffer = deque(maxlen=6)\n",
        "        self.position_history = deque(maxlen=15)\n",
        "\n",
        "        # Ultra-sensitive thresholds\n",
        "        self.fall_threshold = 0.25        # Very low threshold\n",
        "        self.motion_threshold = 0.3       # Motion-based detection\n",
        "        self.emergency_threshold = 0.35   # Emergency detection\n",
        "\n",
        "        # Calibration variables\n",
        "        self.baseline_height = None\n",
        "        self.baseline_width = None\n",
        "        self.frame_count = 0\n",
        "        self.calibration_complete = False\n",
        "\n",
        "        # MoveNet keypoint indices\n",
        "        self.keypoints = {\n",
        "            'nose': 0, 'left_eye': 1, 'right_eye': 2, 'left_ear': 3, 'right_ear': 4,\n",
        "            'left_shoulder': 5, 'right_shoulder': 6, 'left_elbow': 7, 'right_elbow': 8,\n",
        "            'left_wrist': 9, 'right_wrist': 10, 'left_hip': 11, 'right_hip': 12,\n",
        "            'left_knee': 13, 'right_knee': 14, 'left_ankle': 15, 'right_ankle': 16\n",
        "        }\n",
        "\n",
        "        # Previous frame data\n",
        "        self.prev_frame = None\n",
        "        self.prev_keypoints = None\n",
        "        self.fall_sequence_counter = 0\n",
        "\n",
        "        print(\" Ultra-Accurate Fall Detector initialized!\")\n",
        "\n",
        "    def preprocess_frame(self, frame):\n",
        "        \"\"\"Preprocess frame for MoveNet\"\"\"\n",
        "        # Resize to 192x192 for MoveNet Lightning\n",
        "        resized = cv2.resize(frame, (192, 192))\n",
        "        rgb_frame = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
        "        input_tensor = tf.cast(rgb_frame, dtype=tf.int32)\n",
        "        input_tensor = tf.expand_dims(input_tensor, axis=0)\n",
        "        return input_tensor\n",
        "\n",
        "    def detect_pose(self, frame):\n",
        "        \"\"\"Get pose keypoints using MoveNet\"\"\"\n",
        "        input_tensor = self.preprocess_frame(frame)\n",
        "        outputs = self.movenet(input_tensor)\n",
        "        keypoints = outputs['output_0'].numpy()[0, 0, :, :]\n",
        "        return keypoints\n",
        "\n",
        "    def get_keypoint_coords(self, keypoints, name, frame_shape):\n",
        "        \"\"\"Get keypoint coordinates with confidence check\"\"\"\n",
        "        h, w = frame_shape[:2]\n",
        "        idx = self.keypoints[name]\n",
        "        y, x, conf = keypoints[idx]\n",
        "\n",
        "        if conf > 0.2:  # Very low confidence threshold\n",
        "            return int(y * h), int(x * w), conf\n",
        "        return None, None, 0.0\n"
      ],
      "metadata": {
        "id": "5bbT8kIMLVZ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def extract_comprehensive_features(self, keypoints, frame):\n",
        "        \"\"\"Extract multiple types of features for fall detection\"\"\"\n",
        "        h, w = frame.shape[:2]\n",
        "        features = {}\n",
        "\n",
        "        # Get key body points\n",
        "        nose_y, nose_x, nose_conf = self.get_keypoint_coords(keypoints, 'nose', frame.shape)\n",
        "        l_shoulder_y, l_shoulder_x, l_shoulder_conf = self.get_keypoint_coords(keypoints, 'left_shoulder', frame.shape)\n",
        "        r_shoulder_y, r_shoulder_x, r_shoulder_conf = self.get_keypoint_coords(keypoints, 'right_shoulder', frame.shape)\n",
        "        l_hip_y, l_hip_x, l_hip_conf = self.get_keypoint_coords(keypoints, 'left_hip', frame.shape)\n",
        "        r_hip_y, r_hip_x, r_hip_conf = self.get_keypoint_coords(keypoints, 'right_hip', frame.shape)\n",
        "        l_ankle_y, l_ankle_x, l_ankle_conf = self.get_keypoint_coords(keypoints, 'left_ankle', frame.shape)\n",
        "        r_ankle_y, r_ankle_x, r_ankle_conf = self.get_keypoint_coords(keypoints, 'right_ankle', frame.shape)\n",
        "\n",
        "        # Calculate body center points\n",
        "        valid_shoulders = [(y, x) for y, x, c in [(l_shoulder_y, l_shoulder_x, l_shoulder_conf),\n",
        "                                                  (r_shoulder_y, r_shoulder_x, r_shoulder_conf)] if c > 0.2]\n",
        "        valid_hips = [(y, x) for y, x, c in [(l_hip_y, l_hip_x, l_hip_conf),\n",
        "                                             (r_hip_y, r_hip_x, r_hip_conf)] if c > 0.2]\n",
        "        valid_ankles = [(y, x) for y, x, c in [(l_ankle_y, l_ankle_x, l_ankle_conf),\n",
        "                                              (r_ankle_y, r_ankle_x, r_ankle_conf)] if c > 0.2]\n",
        "\n",
        "        if not valid_shoulders or not valid_hips:\n",
        "            return None\n",
        "\n",
        "        # Average positions for stability\n",
        "        shoulder_center = np.mean(valid_shoulders, axis=0)\n",
        "        hip_center = np.mean(valid_hips, axis=0)\n",
        "\n",
        "        # 1. BODY HEIGHT ANALYSIS\n",
        "        if valid_ankles:\n",
        "            ankle_center = np.mean(valid_ankles, axis=0)\n",
        "            current_height = abs(shoulder_center[0] - ankle_center[0])\n",
        "        else:\n",
        "            # Estimate ankle position\n",
        "            current_height = abs(shoulder_center[0] - hip_center[0]) * 2.5\n",
        "\n",
        "        # Calibration\n",
        "        if not self.calibration_complete:\n",
        "            if self.baseline_height is None:\n",
        "                self.baseline_height = current_height\n",
        "            else:\n",
        "                self.baseline_height = max(self.baseline_height, current_height)\n",
        "\n",
        "            self.frame_count += 1\n",
        "            if self.frame_count >= 3:  # Quick calibration\n",
        "                self.calibration_complete = True\n",
        "\n",
        "        if self.baseline_height and self.baseline_height > 0:\n",
        "            height_ratio = current_height / self.baseline_height\n",
        "            features['height_ratio'] = height_ratio\n",
        "        else:\n",
        "            features['height_ratio'] = 1.0\n",
        "\n",
        "        # 2. BODY ORIENTATION ANALYSIS\n",
        "        torso_vector = hip_center - shoulder_center\n",
        "        torso_angle = abs(math.degrees(math.atan2(torso_vector[1], torso_vector[0])))\n",
        "\n",
        "        # Normalize angle (0-90 degrees)\n",
        "        if torso_angle > 90:\n",
        "            torso_angle = 180 - torso_angle\n",
        "\n",
        "        features['torso_angle'] = torso_angle\n",
        "\n",
        "        # 3. VERTICAL POSITION ANALYSIS\n",
        "        if nose_y is not None:\n",
        "            head_position = nose_y / h\n",
        "        else:\n",
        "            head_position = shoulder_center[0] / h\n",
        "\n",
        "        features['head_height'] = 1.0 - head_position  # Invert so lower = smaller value\n",
        "\n",
        "        # 4. BODY COMPACTNESS\n",
        "        all_points = []\n",
        "        for name in self.keypoints.keys():\n",
        "            y, x, conf = self.get_keypoint_coords(keypoints, name, frame.shape)\n",
        "            if conf > 0.2:\n",
        "                all_points.append([y, x])\n",
        "\n",
        "        if len(all_points) >= 4:\n",
        "            all_points = np.array(all_points)\n",
        "            bbox_height = np.max(all_points[:, 0]) - np.min(all_points[:, 0])\n",
        "            bbox_width = np.max(all_points[:, 1]) - np.min(all_points[:, 1])\n",
        "\n",
        "            if bbox_height > 0:\n",
        "                aspect_ratio = bbox_width / bbox_height\n",
        "                features['aspect_ratio'] = aspect_ratio\n",
        "            else:\n",
        "                features['aspect_ratio'] = 0\n",
        "        else:\n",
        "            features['aspect_ratio'] = 0\n",
        "\n",
        "        # 5. MOTION ANALYSIS\n",
        "        current_center = (shoulder_center + hip_center) / 2\n",
        "\n",
        "        if self.prev_keypoints is not None:\n",
        "            # Calculate movement\n",
        "            prev_shoulder = np.mean([(y, x) for y, x, c in [(self.get_keypoint_coords(self.prev_keypoints, 'left_shoulder', frame.shape)[0:2] + (self.get_keypoint_coords(self.prev_keypoints, 'left_shoulder', frame.shape)[2],)),\n",
        "                                                           (self.get_keypoint_coords(self.prev_keypoints, 'right_shoulder', frame.shape)[0:2] + (self.get_keypoint_coords(self.prev_keypoints, 'right_shoulder', frame.shape)[2],))] if c > 0.2], axis=0) if len([(y, x) for y, x, c in [(self.get_keypoint_coords(self.prev_keypoints, 'left_shoulder', frame.shape)[0:2] + (self.get_keypoint_coords(self.prev_keypoints, 'left_shoulder', frame.shape)[2],)),\n",
        "                                                           (self.get_keypoint_coords(self.prev_keypoints, 'right_shoulder', frame.shape)[0:2] + (self.get_keypoint_coords(self.prev_keypoints, 'right_shoulder', frame.shape)[2],))] if c > 0.2]) > 0 else current_center\n",
        "\n",
        "            movement = np.linalg.norm(current_center - prev_shoulder) / h\n",
        "            features['movement_speed'] = movement\n",
        "\n",
        "            # Vertical movement (downward motion)\n",
        "            vertical_movement = (current_center[0] - prev_shoulder[0]) / h\n",
        "            features['vertical_movement'] = max(0, vertical_movement)  # Only downward\n",
        "        else:\n",
        "            features['movement_speed'] = 0\n",
        "            features['vertical_movement'] = 0\n",
        "\n",
        "        self.prev_keypoints = keypoints.copy()\n",
        "        return features\n",
        "\n",
        "# Add the method to the class\n",
        "UltraAccurateFallDetector.extract_comprehensive_features = extract_comprehensive_features\n"
      ],
      "metadata": {
        "id": "RFNbmbvZLiaz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def multi_level_fall_detection(self, features):\n",
        "        \"\"\"Multi-level fall detection with three detection pathways\"\"\"\n",
        "        if features is None:\n",
        "            return False, 0.0, \"No valid pose detected\"\n",
        "\n",
        "        detection_scores = {}\n",
        "        reasons = []\n",
        "\n",
        "        # LEVEL 1: PRIMARY POSE-BASED DETECTION\n",
        "        primary_indicators = {\n",
        "            'severe_height_loss': features.get('height_ratio', 1.0) < 0.4,\n",
        "            'moderate_height_loss': features.get('height_ratio', 1.0) < 0.6,\n",
        "            'horizontal_body': features.get('torso_angle', 0) > 45,\n",
        "            'very_horizontal_body': features.get('torso_angle', 0) > 70,\n",
        "            'low_head_position': features.get('head_height', 1.0) < 0.3,\n",
        "            'wide_aspect_ratio': features.get('aspect_ratio', 0) > 1.5\n",
        "        }\n",
        "\n",
        "        primary_score = 0\n",
        "        if primary_indicators['severe_height_loss']:\n",
        "            primary_score += 0.4\n",
        "            reasons.append(\"Severe height reduction\")\n",
        "        elif primary_indicators['moderate_height_loss']:\n",
        "            primary_score += 0.2\n",
        "            reasons.append(\"Height reduction\")\n",
        "\n",
        "        if primary_indicators['very_horizontal_body']:\n",
        "            primary_score += 0.3\n",
        "            reasons.append(\"Body horizontal\")\n",
        "        elif primary_indicators['horizontal_body']:\n",
        "            primary_score += 0.15\n",
        "\n",
        "        if primary_indicators['low_head_position']:\n",
        "            primary_score += 0.2\n",
        "            reasons.append(\"Head near ground\")\n",
        "\n",
        "        if primary_indicators['wide_aspect_ratio']:\n",
        "            primary_score += 0.15\n",
        "            reasons.append(\"Body spread horizontally\")\n",
        "\n",
        "        detection_scores['primary'] = primary_score\n",
        "\n",
        "        # LEVEL 2: MOTION-BASED DETECTION\n",
        "        motion_score = 0\n",
        "        motion_features = {\n",
        "            'rapid_descent': features.get('vertical_movement', 0) > 0.1,\n",
        "            'high_movement': features.get('movement_speed', 0) > 0.15\n",
        "        }\n",
        "\n",
        "        if motion_features['rapid_descent']:\n",
        "            motion_score += 0.3\n",
        "            reasons.append(\"Rapid downward motion\")\n",
        "\n",
        "        if motion_features['high_movement']:\n",
        "            motion_score += 0.2\n",
        "            reasons.append(\"High movement speed\")\n",
        "\n",
        "        detection_scores['motion'] = motion_score\n",
        "\n",
        "        # LEVEL 3: EMERGENCY DETECTION (Immediate response)\n",
        "        emergency_conditions = [\n",
        "            features.get('height_ratio', 1.0) < 0.3,  # Extreme height loss\n",
        "            features.get('torso_angle', 0) > 80,      # Nearly horizontal\n",
        "            features.get('head_height', 1.0) < 0.2,  # Head very low\n",
        "            (features.get('aspect_ratio', 0) > 2.0 and features.get('height_ratio', 1.0) < 0.5)\n",
        "        ]\n",
        "\n",
        "        emergency_score = 0.8 if any(emergency_conditions) else 0\n",
        "        if emergency_score > 0:\n",
        "            reasons.append(\"EMERGENCY: Extreme fall indicators\")\n",
        "        detection_scores['emergency'] = emergency_score\n",
        "\n",
        "        # FUSION: Combine all detection methods\n",
        "        final_score = max(\n",
        "            detection_scores['primary'],\n",
        "            detection_scores['motion'] * 0.7,  # Motion detection weighted lower\n",
        "            detection_scores['emergency']\n",
        "        )\n",
        "\n",
        "        # Boost score if multiple detectors agree\n",
        "        if detection_scores['primary'] > 0.1 and detection_scores['motion'] > 0.1:\n",
        "            final_score += 0.1\n",
        "            reasons.append(\"Multiple detectors agree\")\n",
        "\n",
        "        is_fall = final_score > self.fall_threshold\n",
        "        reason_text = \"; \".join(reasons) if reasons else \"Normal activity\"\n",
        "\n",
        "        return is_fall, final_score, reason_text\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        \"\"\"Process single frame with comprehensive analysis\"\"\"\n",
        "        # Extract pose keypoints\n",
        "        keypoints = self.detect_pose(frame)\n",
        "\n",
        "        # Extract features\n",
        "        features = self.extract_comprehensive_features(keypoints, frame)\n",
        "\n",
        "        if features is None:\n",
        "            return False, 0.0, \"No pose detected\", keypoints, None\n",
        "\n",
        "        # Add to buffers\n",
        "        self.pose_buffer.append(features)\n",
        "\n",
        "        # Skip during calibration\n",
        "        if not self.calibration_complete:\n",
        "            return False, 0.0, \"Calibrating...\", keypoints, features\n",
        "\n",
        "        # Multi-level detection\n",
        "        is_fall, fall_score, reason = self.multi_level_fall_detection(features)\n",
        "\n",
        "        # Temporal smoothing - require consistency\n",
        "        if len(self.pose_buffer) >= 3:\n",
        "            recent_features = list(self.pose_buffer)[-3:]\n",
        "            fall_votes = 0\n",
        "\n",
        "            for feat in recent_features:\n",
        "                temp_fall, temp_score, _ = self.multi_level_fall_detection(feat)\n",
        "                if temp_fall or temp_score > 0.2:  # Very low threshold\n",
        "                    fall_votes += 1\n",
        "\n",
        "            # More aggressive temporal logic\n",
        "            if fall_score > 0.5:  # High confidence - immediate response\n",
        "                final_decision = True\n",
        "            elif fall_votes >= 2:  # Majority vote\n",
        "                final_decision = True\n",
        "            else:\n",
        "                final_decision = is_fall\n",
        "        else:\n",
        "            final_decision = is_fall\n",
        "\n",
        "        # Track fall sequences\n",
        "        if final_decision:\n",
        "            self.fall_sequence_counter += 1\n",
        "        else:\n",
        "            self.fall_sequence_counter = max(0, self.fall_sequence_counter - 1)\n",
        "\n",
        "        return final_decision, fall_score, reason, keypoints, features\n",
        "\n",
        "# Add methods to the class\n",
        "UltraAccurateFallDetector.multi_level_fall_detection = multi_level_fall_detection\n",
        "UltraAccurateFallDetector.process_frame = process_frame\n"
      ],
      "metadata": {
        "id": "cpxM2sOILk6C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_advanced_visualization(self, frame, keypoints, is_fall, fall_score, reason, features):\n",
        "    \"\"\"Advanced visualization with detailed information - COMPACT VERSION\"\"\"\n",
        "    h, w = frame.shape[:2]\n",
        "\n",
        "    # Skeleton connections\n",
        "    connections = [\n",
        "        ('nose', 'left_eye'), ('nose', 'right_eye'),\n",
        "        ('left_shoulder', 'right_shoulder'),\n",
        "        ('left_shoulder', 'left_elbow'), ('left_elbow', 'left_wrist'),\n",
        "        ('right_shoulder', 'right_elbow'), ('right_elbow', 'right_wrist'),\n",
        "        ('left_shoulder', 'left_hip'), ('right_shoulder', 'right_hip'),\n",
        "        ('left_hip', 'right_hip'),\n",
        "        ('left_hip', 'left_knee'), ('left_knee', 'left_ankle'),\n",
        "        ('right_hip', 'right_knee'), ('right_knee', 'right_ankle')\n",
        "    ]\n",
        "\n",
        "    # Dynamic coloring based on fall confidence\n",
        "    if is_fall:\n",
        "        if fall_score > 0.7:\n",
        "            skeleton_color = (0, 0, 255)    # Bright red - definite fall\n",
        "            status_color = (0, 0, 255)\n",
        "            status_text = \" FALL DETECTED! \"\n",
        "        else:\n",
        "            skeleton_color = (0, 100, 255)  # Orange-red - likely fall\n",
        "            status_color = (0, 100, 255)\n",
        "            status_text = \"!!!\"\n",
        "    elif fall_score > 0.35:\n",
        "        skeleton_color = (0, 200, 255)      # Orange - warning\n",
        "        status_color = (0, 200, 255)\n",
        "        status_text = \" Potential Risk\"\n",
        "    else:\n",
        "        skeleton_color = (0, 255, 0)        # Green - normal\n",
        "        status_color = (0, 255, 0)\n",
        "        status_text = \" Normal\"\n",
        "\n",
        "    # Draw skeleton\n",
        "    for connection in connections:\n",
        "        start_idx = self.keypoints[connection[0]]\n",
        "        end_idx = self.keypoints[connection[1]]\n",
        "\n",
        "        start_y, start_x, start_conf = keypoints[start_idx]\n",
        "        end_y, end_x, end_conf = keypoints[end_idx]\n",
        "\n",
        "        if start_conf > 0.2 and end_conf > 0.2:\n",
        "            start_point = (int(start_x * w), int(start_y * h))\n",
        "            end_point = (int(end_x * w), int(end_y * h))\n",
        "            cv2.line(frame, start_point, end_point, skeleton_color, 3)\n",
        "\n",
        "    # Draw keypoints\n",
        "    for i, (y, x, conf) in enumerate(keypoints):\n",
        "        if conf > 0.2:\n",
        "            point = (int(x * w), int(y * h))\n",
        "            cv2.circle(frame, point, 5, skeleton_color, -1)\n",
        "            cv2.circle(frame, point, 7, (255, 255, 255), 2)\n",
        "\n",
        "    # COMPACT Status panel - SINGLE LINE\n",
        "    panel_height = 35  # Reduced from 140 to 35\n",
        "    cv2.rectangle(frame, (0, 0), (w, panel_height), (0, 0, 0), -1)\n",
        "    cv2.rectangle(frame, (0, 0), (w, panel_height), status_color, 2)\n",
        "\n",
        "    # Single line with all info - compact format\n",
        "    if features:\n",
        "        compact_info = f\"{status_text} | Conf:{fall_score:.1%} | H:{features.get('height_ratio', 0):.2f} A:{features.get('torso_angle', 0):.0f}¬∞ | {reason[:30]}{'...' if len(reason) > 30 else ''}\"\n",
        "    else:\n",
        "        compact_info = f\"{status_text} | Conf:{fall_score:.1%} | {reason[:40]}{'...' if len(reason) > 40 else ''}\"\n",
        "\n",
        "    cv2.putText(frame, compact_info, (5, 22),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "    # Fall sequence counter - only if active\n",
        "    if self.fall_sequence_counter > 0:\n",
        "        cv2.putText(frame, f\"Seq:{self.fall_sequence_counter}\", (w-70, 22),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Replace the method in your existing class\n",
        "UltraAccurateFallDetector.draw_advanced_visualization = draw_advanced_visualization\n"
      ],
      "metadata": {
        "id": "b69tADXtLn6R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_ultra_accurate(video_path, output_path=None, display_progress=True):\n",
        "    \"\"\"Ultra-accurate video processing with detailed analysis\"\"\"\n",
        "\n",
        "    print(f\"üé¨ Initializing ultra-accurate fall detection for: {video_path}\")\n",
        "    detector = UltraAccurateFallDetector()\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\" Error: Could not open video file\")\n",
        "        return None\n",
        "\n",
        "    # Video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "\n",
        "    print(f\" Video Info: {width}x{height}, {fps}fps, {total_frames} frames, {duration:.1f}s\")\n",
        "\n",
        "    # Setup output video writer\n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "        print(f\" Output will be saved as: {output_path}\")\n",
        "\n",
        "    # Analysis variables\n",
        "    fall_events = []\n",
        "    current_fall_event = None\n",
        "    frame_count = 0\n",
        "    total_fall_frames = 0\n",
        "    max_confidence = 0\n",
        "\n",
        "    print(\" Starting ultra-accurate analysis...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        current_time = frame_count / fps\n",
        "\n",
        "        # Process frame with ultra-accurate detection\n",
        "        is_fall, fall_score, reason, keypoints, features = detector.process_frame(frame)\n",
        "\n",
        "        # Track maximum confidence seen\n",
        "        max_confidence = max(max_confidence, fall_score)\n",
        "\n",
        "        # Enhanced fall event tracking\n",
        "        if is_fall or fall_score > 0.15:  # Very low threshold for event tracking\n",
        "            total_fall_frames += 1\n",
        "\n",
        "            if current_fall_event is None:\n",
        "                # Start new fall event\n",
        "                current_fall_event = {\n",
        "                    'start_frame': frame_count,\n",
        "                    'start_time': current_time,\n",
        "                    'max_confidence': fall_score,\n",
        "                    'peak_reason': reason,\n",
        "                    'confirmed_fall': is_fall\n",
        "                }\n",
        "            else:\n",
        "                # Update existing event\n",
        "                if fall_score > current_fall_event['max_confidence']:\n",
        "                    current_fall_event['max_confidence'] = fall_score\n",
        "                    current_fall_event['peak_reason'] = reason\n",
        "\n",
        "                if is_fall:\n",
        "                    current_fall_event['confirmed_fall'] = True\n",
        "        else:\n",
        "            # End fall event if it exists\n",
        "            if current_fall_event is not None:\n",
        "                current_fall_event['end_frame'] = frame_count - 1\n",
        "                current_fall_event['end_time'] = (frame_count - 1) / fps\n",
        "                current_fall_event['duration'] = current_fall_event['end_time'] - current_fall_event['start_time']\n",
        "\n",
        "                # Only save significant events\n",
        "                if current_fall_event['duration'] >= 0.5 or current_fall_event['confirmed_fall']:\n",
        "                    fall_events.append(current_fall_event)\n",
        "\n",
        "                current_fall_event = None\n",
        "\n",
        "        # Create visualization\n",
        "        annotated_frame = detector.draw_advanced_visualization(\n",
        "            frame.copy(), keypoints, is_fall, fall_score, reason, features\n",
        "        )\n",
        "\n",
        "        # Write to output video\n",
        "        if output_path:\n",
        "            out.write(annotated_frame)\n",
        "\n",
        "        # Progress reporting\n",
        "        if display_progress and frame_count % 30 == 0:\n",
        "            progress = (frame_count / total_frames) * 100\n",
        "            print(f\"üìä Progress: {progress:.1f}% | Frame: {frame_count}/{total_frames} | Falls detected: {len(fall_events)}\")\n",
        "\n",
        "        # Real-time fall alerts\n",
        "        if is_fall and fall_score > 0.5:\n",
        "            print(f\"üö® FALL ALERT at {current_time:.1f}s - Confidence: {fall_score:.1%} - {reason}\")\n",
        "\n",
        "    # Handle final fall event\n",
        "    if current_fall_event is not None:\n",
        "        current_fall_event['end_frame'] = frame_count\n",
        "        current_fall_event['end_time'] = current_time\n",
        "        current_fall_event['duration'] = current_fall_event['end_time'] - current_fall_event['start_time']\n",
        "\n",
        "        if current_fall_event['duration'] >= 0.5 or current_fall_event['confirmed_fall']:\n",
        "            fall_events.append(current_fall_event)\n",
        "\n",
        "    # Cleanup\n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "\n",
        "    # # Comprehensive results analysis\n",
        "    # print(\"\\n\" + \"=\" * 60)\n",
        "    # print(\"üìä ULTRA-ACCURATE FALL DETECTION RESULTS\")\n",
        "    # print(\"=\" * 60)\n",
        "    # print(f\"üé¨ Video: {video_path}\")\n",
        "    # print(f\"üìè Duration: {duration:.1f} seconds ({total_frames} frames)\")\n",
        "    # print(f\"üîç Frames analyzed: {frame_count}\")\n",
        "    # print(f\"‚ö†Ô∏è  Suspicious frames: {total_fall_frames} ({total_fall_frames/frame_count*100:.1f}%)\")\n",
        "    # print(f\"üìà Maximum confidence: {max_confidence:.1%}\")\n",
        "    # print(f\"üö® Fall events detected: {len(fall_events)}\")\n",
        "\n",
        "\n",
        "\n",
        "    return {\n",
        "        'fall_events': fall_events,\n",
        "        'total_frames': frame_count,\n",
        "        'suspicious_frames': total_fall_frames,\n",
        "        'max_confidence': max_confidence,\n",
        "        'video_duration': duration\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Ultra-accurate video processing function ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlbTZKvxLruQ",
        "outputId": "1fcbe316-ab84-448d-ab56-a99182ff40ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ultra-accurate video processing function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload and process video\n",
        "print(\"üìÅ Please upload your video file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    video_filename = list(uploaded.keys())[0]\n",
        "    print(f\"\\n Processing {video_filename} with ULTRA-ACCURATE detection...\")\n",
        "\n",
        "    # Process video with maximum accuracy\n",
        "    results = process_video_ultra_accurate(\n",
        "        video_filename,\n",
        "        output_path='ultra_accurate_fall_detection.mp4',\n",
        "        display_progress=True\n",
        "    )\n",
        "\n",
        "    # Download processed video\n",
        "    if os.path.exists('ultra_accurate_fall_detection.mp4'):\n",
        "        print(\"\\n Download your processed video:\")\n",
        "        files.download('ultra_accurate_fall_detection.mp4')\n",
        "\n",
        "    print(\"\\n Ultra-accurate fall detection complete!\")\n",
        "\n",
        "    # Additional analysis if needed\n",
        "    if results and len(results['fall_events']) == 0:\n",
        "        print(\"\\nüîß TROUBLESHOOTING SUGGESTIONS:\")\n",
        "        print(\"1. The person might be too small in the frame - try closer camera angle\")\n",
        "        print(\"2. Lighting conditions might be poor - ensure good visibility\")\n",
        "        print(\"3. Multiple people in frame - system works best with single person\")\n",
        "        print(\"4. Very quick falls might need even lower thresholds\")\n",
        "\n",
        "        # Offer to re-run with even more sensitive settings\n",
        "        user_input = input(\"\\n Would you like to re-run with MAXIMUM sensitivity? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            print(\" Re-running with MAXIMUM sensitivity...\")\n",
        "\n",
        "            # Create ultra-sensitive detector\n",
        "            detector = UltraAccurateFallDetector()\n",
        "            detector.fall_threshold = 0.15  # Even lower threshold\n",
        "            detector.motion_threshold = 0.2\n",
        "            detector.emergency_threshold = 0.25\n",
        "\n",
        "            results = process_video_ultra_accurate(\n",
        "                video_filename,\n",
        "                output_path='maximum_sensitivity_detection.mp4'\n",
        "            )\n",
        "else:\n",
        "    print(\"‚ùå No video file uploaded. Please run this cell again and upload a video.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z638X8ebLvS6",
        "outputId": "d1a774b5-883c-4677-8a0f-6accd1547646"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Please upload your video file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2eec6416-243a-4369-b7e2-fff955ef9cfa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2eec6416-243a-4369-b7e2-fff955ef9cfa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving istockphoto-1066783428-640_adpp_is.mp4 to istockphoto-1066783428-640_adpp_is.mp4\n",
            "\n",
            " Processing istockphoto-1066783428-640_adpp_is.mp4 with ULTRA-ACCURATE detection...\n",
            "üé¨ Initializing ultra-accurate fall detection for: istockphoto-1066783428-640_adpp_is.mp4\n",
            " Loading MoveNet model...\n",
            " MoveNet model loaded!\n",
            " Ultra-Accurate Fall Detector initialized!\n",
            " Video Info: 768x432, 23fps, 272 frames, 11.8s\n",
            " Output will be saved as: ultra_accurate_fall_detection.mp4\n",
            " Starting ultra-accurate analysis...\n",
            "============================================================\n",
            "üìä Progress: 11.0% | Frame: 30/272 | Falls detected: 0\n",
            "üìä Progress: 22.1% | Frame: 60/272 | Falls detected: 0\n",
            "üìä Progress: 33.1% | Frame: 90/272 | Falls detected: 1\n",
            "üö® FALL ALERT at 4.8s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 4.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 4.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.1s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 44.1% | Frame: 120/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 5.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.6s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.6s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 5.9s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.0s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.0s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.1s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.1s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.2s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.4s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.5s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 55.1% | Frame: 150/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 6.5s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.6s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 6.6s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.7s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.7s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.8s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.8s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.9s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 6.9s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.0s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.0s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.0s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.1s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.1s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.2s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 7.2s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 7.3s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 7.3s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 7.3s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 7.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.6s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.8s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 66.2% | Frame: 180/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 7.8s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 7.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.0s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.0s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.1s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.2s - Confidence: 95.0% - Severe height reduction; Body horizontal; Body spread horizontally; High movement speed; EMERGENCY: Extreme fall indicators; Multiple detectors agree\n",
            "üö® FALL ALERT at 8.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.3s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.4s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.4s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.5s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.5s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.6s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.6s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.7s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.7s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.7s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 8.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.0s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.1s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 77.2% | Frame: 210/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 9.1s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.5s - Confidence: 80.0% - Height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.6s - Confidence: 80.0% - Height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.6s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 9.9s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.0s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.0s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.0s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.1s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.1s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.2s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.2s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.3s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.3s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.3s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.4s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 88.2% | Frame: 240/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 10.4s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.5s - Confidence: 80.0% - Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.5s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.6s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.6s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.7s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.7s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.8s - Confidence: 80.0% - Height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 10.9s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.0s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.0s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.1s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.1s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.2s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.2s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.3s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.3s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.4s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.5s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.5s - Confidence: 80.0% - Severe height reduction; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.6s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.7s - Confidence: 65.0% - Height reduction; Body horizontal; Body spread horizontally\n",
            "üö® FALL ALERT at 11.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üìä Progress: 99.3% | Frame: 270/272 | Falls detected: 4\n",
            "üö® FALL ALERT at 11.7s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.8s - Confidence: 85.0% - Severe height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "üö® FALL ALERT at 11.8s - Confidence: 80.0% - Height reduction; Body horizontal; Body spread horizontally; EMERGENCY: Extreme fall indicators\n",
            "\n",
            " Download your processed video:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8beef29a-a2ed-45bd-96b1-ca5e15fc2634\", \"ultra_accurate_fall_detection.mp4\", 6289866)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ultra-accurate fall detection complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbud9W7xLyb9"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}